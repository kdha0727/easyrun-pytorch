{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS version: \t\tmacOS-11.5.1-arm64-arm-64bit\n",
      "Python version:\t\t3.8.10 | packaged by conda-forge\n",
      "Torch version:\t\t1.8.0\n",
      "Torch device:\t\tcpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from easyrun import runtime_info, dataset_info, Easyrun\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(runtime_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dataset Information>\n",
      "Train Dataset: \t\t50000\n",
      "Validation Dataset: \t10000\n",
      "Test Dataset: \t\t10000\n"
     ]
    }
   ],
   "source": [
    "train_set = MNIST(\"MNIST_data/\", train=True, transform=ToTensor(), download=True)\n",
    "test_set = MNIST(\"MNIST_data/\", train=False, transform=ToTensor(), download=True)\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [50000, 10000])\n",
    "\n",
    "print(dataset_info(train_set, val_set, test_set, loader=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DataLoader Information>\n",
      "Train Batch: \t\t781\n",
      "Validation Batch: \t156\n",
      "Test Batch: \t\t156\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=64, shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set, batch_size=64, shuffle=False, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=64, shuffle=False, drop_last=True)\n",
    "\n",
    "print(dataset_info(train_loader, val_loader, test_loader, loader=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model = type('Example', (torch.nn.Module, ), {'forward': lambda self, x: self.inner(x.view(-1, 784))})()\n",
    "model.inner = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28 * 28, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 10),\n",
    "    torch.nn.Softmax(1)\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<Start Learning> \t\t\t\tTotal 10 epochs\n",
      "\n",
      "Epoch 1\n",
      "[Train]\t Progress: 50000/50000 (100.00%), \tTrain Done!      \n",
      "[Eval]\t Average loss: 1.56226, \t\tTotal accuracy: 91.13%\n",
      "\n",
      "Epoch 2\n",
      "[Train]\t Progress: 50000/50000 (100.00%), \tTrain Done!      \n",
      "[Eval]\t Average loss: 1.54006, \t\tTotal accuracy: 92.99%\n",
      "\n",
      "Epoch 3\n",
      "[Train]\t Progress: 50000/50000 (100.00%), \tTrain Done!      \n",
      "[Eval]\t Average loss: 1.53063, \t\tTotal accuracy: 93.72%\n",
      "\n",
      "Epoch 4\n",
      "[Train]\t Progress: 50000/50000 (100.00%), \tTrain Done!      \n",
      "[Eval]\t Average loss: 1.52538, \t\tTotal accuracy: 94.18%\n",
      "\n",
      "Epoch 5\n",
      "[Train]\t Progress: 50000/50000 (100.00%), \tTrain Done!      \n",
      "[Eval]\t Average loss: 1.51565, \t\tTotal accuracy: 95.12%\n",
      "\n",
      "Epoch 6\n",
      "[Train]\t Progress: 50000/50000 (100.00%), \tTrain Done!      \n",
      "[Eval]\t Average loss: 1.51174, \t\tTotal accuracy: 95.37%\n",
      "\n",
      "Epoch 7\n",
      "[Train]\t Progress: 50000/50000 (100.00%), \tTrain Done!      \n",
      "[Eval]\t Average loss: 1.51048, \t\tTotal accuracy: 95.45%\n",
      "\n",
      "Epoch 8\n",
      "[Train]\t Progress: 50000/50000 (100.00%), \tTrain Done!      \n",
      "[Eval]\t Average loss: 1.50815, \t\tTotal accuracy: 95.69%\n",
      "\n",
      "Epoch 9\n",
      "[Train]\t Progress: 50000/50000 (100.00%), \tTrain Done!      \n",
      "[Eval]\t Average loss: 1.50476, \t\tTotal accuracy: 95.90%\n",
      "\n",
      "Epoch 10\n",
      "[Train]\t Progress: 50000/50000 (100.00%), \tTrain Done!      \n",
      "[Eval]\t Average loss: 1.50283, \t\tTotal accuracy: 96.06%\n",
      "\n",
      "<Stop Learning> \tLeast loss: 1.5028\tDuration: 31.02s\n",
      "\n",
      "[Test]\t Average loss: 1.50160, \t\tTotal accuracy: 96.21%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with Easyrun(\n",
    "        model, 'CrossEntropyLoss', optimizer, epochs,\n",
    "        train_loader, val_loader, test_loader,\n",
    "        verbose=True, timer=True, snapshot_dir='.',\n",
    ") as trainer:\n",
    "    trainer.to(device)\n",
    "    trainer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}